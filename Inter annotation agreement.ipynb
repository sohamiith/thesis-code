{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65ebf662",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kappa() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     26\u001b[0m captions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA cat is sitting on a mat.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA cat is lying on a mat.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA cat is playing with a toy.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA cat is grooming itself.\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     28\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA dog is running in a field.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA dog is chasing a ball.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA dog is barking loudly.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA dog is wagging its tail.\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# ... Add captions for the remaining images\u001b[39;00m\n\u001b[1;32m     30\u001b[0m ]\n\u001b[0;32m---> 32\u001b[0m pairwise_agreements \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pairwise_agreement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Print the pairwise agreements\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, agreement_score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pairwise_agreements):\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mcalculate_pairwise_agreement\u001b[0;34m(captions)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate pairwise agreements for all combinations\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m combinations(\u001b[38;5;28mrange\u001b[39m(num_captions), \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     agreement_score \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     pairwise_agreements\u001b[38;5;241m.\u001b[39mappend(agreement_score)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pairwise_agreements\n",
      "\u001b[0;31mTypeError\u001b[0m: kappa() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from nltk import agreement\n",
    "\n",
    "def calculate_pairwise_agreement(captions):\n",
    "    taskdata = []\n",
    "    num_captions = len(captions[0])\n",
    "    \n",
    "    # Generate task data in the required format\n",
    "    for i, img_captions in enumerate(captions):\n",
    "        for j, caption in enumerate(img_captions):\n",
    "            taskdata.append((j, i, caption))\n",
    "    \n",
    "    # Initialize the annotation task\n",
    "    task = agreement.AnnotationTask(data=taskdata)\n",
    "    \n",
    "    pairwise_agreements = []\n",
    "    \n",
    "    # Calculate pairwise agreements for all combinations\n",
    "    for pair in combinations(range(num_captions), 2):\n",
    "        agreement_score = task.kappa(pair)\n",
    "        pairwise_agreements.append(agreement_score)\n",
    "    \n",
    "    return pairwise_agreements\n",
    "\n",
    "# Example usage\n",
    "captions = [\n",
    "    ['A cat is sitting on a mat.', 'A cat is lying on a mat.', 'A cat is playing with a toy.', 'A cat is grooming itself.'],\n",
    "    ['A dog is running in a field.', 'A dog is chasing a ball.', 'A dog is barking loudly.', 'A dog is wagging its tail.'],\n",
    "    # ... Add captions for the remaining images\n",
    "]\n",
    "\n",
    "pairwise_agreements = calculate_pairwise_agreement(captions)\n",
    "\n",
    "# Print the pairwise agreements\n",
    "for i, agreement_score in enumerate(pairwise_agreements):\n",
    "    print(f\"Pair {i+1}: Agreement = {agreement_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36be8d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nltk) (4.65.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff73035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad099f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576344b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m hypothesis \u001b[38;5;241m=\u001b[39m [caption\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m caption \u001b[38;5;129;01min\u001b[39;00m hypothesis]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Compute BLEU score\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m bleu_score \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbleu_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentence_bleu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Print the BLEU score\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBLEU score for captions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbleu_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.9/site-packages/nltk/translate/bleu_score.py:107\u001b[0m, in \u001b[0;36msentence_bleu\u001b[0;34m(references, hypothesis, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentence_bleu\u001b[39m(\n\u001b[1;32m     21\u001b[0m     references,\n\u001b[1;32m     22\u001b[0m     hypothesis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     auto_reweigh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m ):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Calculate BLEU score (Bilingual Evaluation Understudy) from\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    :rtype: float / list(float)\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorpus_bleu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_reweigh\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.9/site-packages/nltk/translate/bleu_score.py:210\u001b[0m, in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m references, hypothesis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(list_of_references, hypotheses):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# For each order of ngram, calculate the numerator and\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# denominator for the corpus-level modified precision.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_weight_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m         p_i \u001b[38;5;241m=\u001b[39m \u001b[43mmodified_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m         p_numerators[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_i\u001b[38;5;241m.\u001b[39mnumerator\n\u001b[1;32m    212\u001b[0m         p_denominators[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_i\u001b[38;5;241m.\u001b[39mdenominator\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.9/site-packages/nltk/translate/bleu_score.py:347\u001b[0m, in \u001b[0;36mmodified_precision\u001b[0;34m(references, hypothesis, n)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03mCalculate modified ngram precision.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m:rtype: Fraction\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Extracts all ngrams in hypothesis\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# Set an empty Counter if hypothesis is empty.\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m counts \u001b[38;5;241m=\u001b[39m \u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(hypothesis) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n \u001b[38;5;28;01melse\u001b[39;00m Counter()\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Extract a union of references' counts.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# max_counts = reduce(or_, [Counter(ngrams(ref, n)) for ref in references])\u001b[39;00m\n\u001b[1;32m    350\u001b[0m max_counts \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.9/collections/__init__.py:593\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m \n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.9/collections/__init__.py:679\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Example captions\n",
    "captions = [\n",
    "    ['A cat is sitting on a mat.', 'A black cat is on a mat.', 'A cat is resting on a mat.', 'A cat is lying on a mat.'],\n",
    "    ['A dog is running in a field.', 'A brown dog is running.', 'A dog is chasing a ball.', 'A dog is playing in the grass.']\n",
    "]\n",
    "\n",
    "# Compute BLEU score for pairwise captions\n",
    "for i in range(len(captions)):\n",
    "    for j in range(i + 1, len(captions)):\n",
    "        references = captions[i]\n",
    "        hypothesis = captions[j]\n",
    "        \n",
    "        # Tokenize the captions\n",
    "        references = [caption.split() for caption in references]\n",
    "        hypothesis = [caption.split() for caption in hypothesis]\n",
    "        \n",
    "        # Compute BLEU score\n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu(references, hypothesis)\n",
    "        \n",
    "        # Print the BLEU score\n",
    "        print(f'BLEU score for captions {i+1} and {j+1}: {bleu_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a202b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat is sitting on a mat.\n",
      "A black cat is on a mat.\n",
      "A cat is resting on a mat.\n",
      "A cat is lying on a mat.\n",
      "A dog is running in a field.\n",
      "A brown dog is running.\n",
      "A dog is chasing a ball.\n",
      "A dog is playing in the grass.\n",
      "BLEU score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Example captions\n",
    "captions = [\n",
    "    ['A cat is sitting on a mat.', 'A black cat is on a mat.', 'A cat is resting on a mat.', 'A cat is lying on a mat.'],\n",
    "    ['A dog is running in a field.', 'A brown dog is running.', 'A dog is chasing a ball.', 'A dog is playing in the grass.']\n",
    "]\n",
    "\n",
    "\n",
    "references = []\n",
    "hypotheses = []\n",
    "bleu = []\n",
    "\n",
    "for i in range(len(captions)):\n",
    "    current_image = captions[i]\n",
    "    for j in len(current_image):\n",
    "        print(caption)\n",
    "    #print(captions[i])\n",
    "    references.append([caption.split() for caption in captions[i]])\n",
    "    hypotheses.append(captions[i][0].split())  # Use the first caption as hypothesis\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_score = nltk.translate.bleu_score.corpus_bleu(references, hypotheses)\n",
    "\n",
    "# Print the BLEU score\n",
    "print(f'BLEU score: {bleu_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12129aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d61aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6dfefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bcdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e19aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find BLEU Score between the pairs of captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a13bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9cbe5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bleu(captions):\n",
    "    all_bleu_score = []\n",
    "    # Compute pairwise BLEU score for each image\n",
    "    for image_captions in captions:\n",
    "        # Prepare references and hypotheses\n",
    "        references = [caption.lower() for caption in image_captions]\n",
    "        #print(references)\n",
    "        pairwise_scores = []\n",
    "\n",
    "        # Compute BLEU score for pairwise captions\n",
    "        for i in range(len(references)):\n",
    "            for j in range(i + 1, len(references)):\n",
    "\n",
    "                #print([references[i]])\n",
    "                #print([references[j]])\n",
    "                # Compute BLEU score\n",
    "                bleu_score = nltk.translate.bleu_score.corpus_bleu([references[i]], [references[j]],weights=(0.5, 0.5, 0, 0))\n",
    "                pairwise_scores.append(bleu_score)\n",
    "\n",
    "        # Print the pairwise BLEU scores for the image\n",
    "        #print(f'Pairwise BLEU scores for image: {pairwise_scores}')\n",
    "        all_bleu_score.append(pairwise_scores)\n",
    "    print(len(all_bleu_score))\n",
    "    return all_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3feff347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48bcbcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Caption 1</th>\n",
       "      <th>Caption 2</th>\n",
       "      <th>Caption 3</th>\n",
       "      <th>Cpation 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>An aerial view of a town with lots of building...</td>\n",
       "      <td>A town with lots of tall buildings and trees</td>\n",
       "      <td>an aerial view of a town with tall buildings</td>\n",
       "      <td>A group of under construction buildings in a t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An aerial view of a town with lots of building...</td>\n",
       "      <td>A town with many buildings and trees</td>\n",
       "      <td>A lot of buildings in a town surrounded by gre...</td>\n",
       "      <td>an aerial view of a town with many buildings a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>An aerial view of a town with lots of building...</td>\n",
       "      <td>A town with lots of tall buildings around</td>\n",
       "      <td>an aerial view of a city with many buildings</td>\n",
       "      <td>A lot of buildings in a town with green trees ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>An aerial view of a under construction site</td>\n",
       "      <td>Many under construction building on a green field</td>\n",
       "      <td>Many new buildings are being built in the midd...</td>\n",
       "      <td>An aerial view of a under construction buildin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>An aerial view of a town with lots of trees an...</td>\n",
       "      <td>A large town with lots of trees and buildings</td>\n",
       "      <td>an aerial view of the town with buildings and ...</td>\n",
       "      <td>an aerial view of a construction site in a tow...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1252</td>\n",
       "      <td>a parking lot with lot of cars parked in it</td>\n",
       "      <td>many cars parked in a parking lot under the tree</td>\n",
       "      <td>a parking lot with many cars and big tree in t...</td>\n",
       "      <td>a parking area has few cars and a tree in it</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1253</td>\n",
       "      <td>a parking lot with lot of cars parked in it</td>\n",
       "      <td>an aerial view of a parking lot filled with ma...</td>\n",
       "      <td>Many cars parked in a parking lot next to walkway</td>\n",
       "      <td>an aerial view of a parking lot with many cars...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1254</td>\n",
       "      <td>a large under construction building</td>\n",
       "      <td>an under consyruction building with many windows</td>\n",
       "      <td>an under construction site with few workers on...</td>\n",
       "      <td>a large building the under construction with w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1255</td>\n",
       "      <td>an under construction building with tall white...</td>\n",
       "      <td>A building is under the construction with many...</td>\n",
       "      <td>three tall white buildings in the background o...</td>\n",
       "      <td>an under construction building has lot of tall...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1256</td>\n",
       "      <td>A car parked in a parking lot</td>\n",
       "      <td>a parking lot next to green bushes</td>\n",
       "      <td>a car parked in a parking lot next to lush gre...</td>\n",
       "      <td>an aerial view of the parking lot with black c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name                                          Caption 1  \\\n",
       "0              1  An aerial view of a town with lots of building...   \n",
       "1              2  An aerial view of a town with lots of building...   \n",
       "2              3  An aerial view of a town with lots of building...   \n",
       "3              4        An aerial view of a under construction site   \n",
       "4              5  An aerial view of a town with lots of trees an...   \n",
       "...          ...                                                ...   \n",
       "1251        1252        a parking lot with lot of cars parked in it   \n",
       "1252        1253        a parking lot with lot of cars parked in it   \n",
       "1253        1254                a large under construction building   \n",
       "1254        1255  an under construction building with tall white...   \n",
       "1255        1256                      A car parked in a parking lot   \n",
       "\n",
       "                                              Caption 2  \\\n",
       "0          A town with lots of tall buildings and trees   \n",
       "1                  A town with many buildings and trees   \n",
       "2             A town with lots of tall buildings around   \n",
       "3     Many under construction building on a green field   \n",
       "4         A large town with lots of trees and buildings   \n",
       "...                                                 ...   \n",
       "1251   many cars parked in a parking lot under the tree   \n",
       "1252  an aerial view of a parking lot filled with ma...   \n",
       "1253   an under consyruction building with many windows   \n",
       "1254  A building is under the construction with many...   \n",
       "1255                 a parking lot next to green bushes   \n",
       "\n",
       "                                              Caption 3  \\\n",
       "0          an aerial view of a town with tall buildings   \n",
       "1     A lot of buildings in a town surrounded by gre...   \n",
       "2          an aerial view of a city with many buildings   \n",
       "3     Many new buildings are being built in the midd...   \n",
       "4     an aerial view of the town with buildings and ...   \n",
       "...                                                 ...   \n",
       "1251  a parking lot with many cars and big tree in t...   \n",
       "1252  Many cars parked in a parking lot next to walkway   \n",
       "1253  an under construction site with few workers on...   \n",
       "1254  three tall white buildings in the background o...   \n",
       "1255  a car parked in a parking lot next to lush gre...   \n",
       "\n",
       "                                              Cpation 4 Unnamed: 5  \n",
       "0     A group of under construction buildings in a t...        NaN  \n",
       "1     an aerial view of a town with many buildings a...        NaN  \n",
       "2     A lot of buildings in a town with green trees ...        NaN  \n",
       "3     An aerial view of a under construction buildin...        NaN  \n",
       "4     an aerial view of a construction site in a tow...        NaN  \n",
       "...                                                 ...        ...  \n",
       "1251       a parking area has few cars and a tree in it        NaN  \n",
       "1252  an aerial view of a parking lot with many cars...        NaN  \n",
       "1253  a large building the under construction with w...        NaN  \n",
       "1254  an under construction building has lot of tall...        NaN  \n",
       "1255  an aerial view of the parking lot with black c...        NaN  \n",
       "\n",
       "[1256 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Image_captions.xlsx\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3b45a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an aerial view of a town with lots of buildings and trees', 'a town with many buildings and trees', 'a lot of buildings in a town surrounded by green trees', 'an aerial view of a town with many buildings and trees']\n"
     ]
    }
   ],
   "source": [
    "l = list()\n",
    "i = 0\n",
    "all_caps = []\n",
    "for index, row in df.iterrows():\n",
    "    first_elem = str(row.iloc[0])\n",
    "    row_elem = row.iloc[1:-1]\n",
    "    current_image = []\n",
    "    for elem in row_elem:\n",
    "        current_image.append(elem.lower())\n",
    "    all_caps.append(current_image)\n",
    "    \n",
    "#print(all_caps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f58b048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1288aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256\n"
     ]
    }
   ],
   "source": [
    "all_bleu_score = find_bleu(all_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e926888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.271934141000531e-155, 9.540741520296657e-155, 7.101760870340493e-155, 9.271934141000531e-155, 7.101760870340493e-155, 7.101760870340493e-155], [9.94445430826712e-155, 8.119612941892116e-155, 8.612150057732663e-155, 8.119612941892116e-155, 8.612150057732663e-155, 8.36950544963808e-155], [9.318377035508748e-155, 9.540741520296657e-155, 8.007015525026118e-155, 8.995097368733392e-155, 7.767946060151122e-155, 8.239151002536468e-155], [7.973301625706314e-155, 7.458340731200295e-155, 7.400746504562499e-155, 8.170202920075766e-155, 7.400746504562499e-155, 7.849677058828354e-155], [9.168333859858698e-155, 8.861829299617244e-155, 7.577681760585021e-155, 8.612150057732663e-155, 7.337058815401293e-155, 7.577681760585021e-155]]\n"
     ]
    }
   ],
   "source": [
    "print(all_bleu_score[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eae48cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa489049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.27193414e-155 9.54074152e-155 7.10176087e-155 9.27193414e-155\n",
      "  7.10176087e-155 7.10176087e-155]\n",
      " [9.94445431e-155 8.11961294e-155 8.61215006e-155 8.11961294e-155\n",
      "  8.61215006e-155 8.36950545e-155]\n",
      " [9.31837704e-155 9.54074152e-155 8.00701553e-155 8.99509737e-155\n",
      "  7.76794606e-155 8.23915100e-155]\n",
      " [7.97330163e-155 7.45834073e-155 7.40074650e-155 8.17020292e-155\n",
      "  7.40074650e-155 7.84967706e-155]\n",
      " [9.16833386e-155 8.86182930e-155 7.57768176e-155 8.61215006e-155\n",
      "  7.33705882e-155 7.57768176e-155]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.array(all_bleu_score)\n",
    "print(numpy_array[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87e7451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair Averages BLEU-2:\n",
      "Pair 1: 8.18256746082274e-155\n",
      "Pair 2: 8.15169051861373e-155\n",
      "Pair 3: 7.946103360874379e-155\n",
      "Pair 4: 8.132993360061177e-155\n",
      "Pair 5: 7.936894907062047e-155\n",
      "Pair 6: 7.978682074370114e-155\n"
     ]
    }
   ],
   "source": [
    "column_averages = np.mean(numpy_array, axis=0)\n",
    "\n",
    "# Print the column averages\n",
    "print(\"Pair Averages BLEU-2:\")\n",
    "for i, average in enumerate(column_averages):\n",
    "    print(f\"Pair {i+1}: {average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0992d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4ca45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb0e080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meteor score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82eff235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/soham/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9886c023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.3599374021909233\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.translate import meteor_score\n",
    "\n",
    "def calculate_meteor_score(generated_caption, reference_caption):\n",
    "    # Convert the captions to lists of words\n",
    "    generated_tokens = generated_caption.split()\n",
    "    reference_tokens = reference_caption.split()\n",
    "\n",
    "    # Calculate the METEOR score\n",
    "    meteor_score_value = meteor_score.meteor_score([reference_tokens], generated_tokens)\n",
    "\n",
    "    return meteor_score_value\n",
    "\n",
    "# Example usage\n",
    "generated_caption = \"The cat is sitting on the mat\"\n",
    "reference_caption = \"A tomcat is jumping on the floor covering\"\n",
    "meteor_score_value = calculate_meteor_score(reference_caption, generated_caption)\n",
    "print(\"METEOR Score:\", meteor_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8fb33e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score -> 0.375\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    \"The cat is sitting on the mat\".split(),\n",
    "]\n",
    "candidate = \"A tomcat is resting on the floor covering\".split()\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9b32b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_wise_meteor = []\n",
    "\n",
    "for curr_caps in all_caps:\n",
    "    curr_score = []\n",
    "    for i in range(len(curr_caps)):\n",
    "        for j in range(i + 1, len(curr_caps)):\n",
    "            curr_score.append(calculate_meteor_score(curr_caps[i],curr_caps[j]))\n",
    "    pair_wise_meteor.append(curr_score)\n",
    "    #print(curr_score)\n",
    "    #print(pair_wise_meteor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "237b9e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256\n"
     ]
    }
   ],
   "source": [
    "print(len(pair_wise_meteor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aba22d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.853494623655914,\n",
       " 0.8064516129032259,\n",
       " 0.5434782608695652,\n",
       " 0.625,\n",
       " 0.49811035525321234,\n",
       " 0.3303703703703704]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_wise_meteor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "624b5759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85349462 0.80645161 0.54347826 0.625      0.49811036 0.33037037]\n",
      " [0.78518519 0.50675676 0.87207207 0.29775943 0.65941471 0.33818182]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array2 = np.array(pair_wise_meteor)\n",
    "print(numpy_array2[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "571eb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair Averages Meteor:\n",
      "Pair 1: 0.43688815155881655\n",
      "Pair 2: 0.3684854914772438\n",
      "Pair 3: 0.3365218251959748\n",
      "Pair 4: 0.34640908880767757\n",
      "Pair 5: 0.3294870956323351\n",
      "Pair 6: 0.3702593029508756\n"
     ]
    }
   ],
   "source": [
    "column_averages = np.mean(numpy_array2, axis=0)\n",
    "\n",
    "# Print the column averages\n",
    "print(\"Pair Averages Meteor:\")\n",
    "for i, average in enumerate(column_averages):\n",
    "    print(f\"Pair {i+1}: {average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf3e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58c824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21291fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "751f6fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f32c418e820>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/rouge/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting rouge\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f32c38ca430>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/32/7c/650ae86f92460e9e8ef969cc5008b24798dcf56a9a8947d04c78f550b3f5/rouge-1.0.1-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f3f1034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Score: 0.18181817685950424\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def calculate_rouge_score(generated_caption, reference_caption):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(generated_caption, reference_caption)\n",
    "    rouge_score = scores[0]['rouge-2']['f']\n",
    "\n",
    "    return rouge_score\n",
    "\n",
    "# Example usage\n",
    "generated_caption = \"A cat is sitting on a mat\"\n",
    "reference_caption = \"A cat sits on the mat\"\n",
    "rouge_score = calculate_rouge_score(generated_caption, reference_caption)\n",
    "print(\"ROUGE Score:\", rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df91d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_wise_rouge = []\n",
    "\n",
    "for curr_caps in all_caps:\n",
    "    curr_score = []\n",
    "    for i in range(len(curr_caps)):\n",
    "        for j in range(i + 1, len(curr_caps)):\n",
    "            curr_score.append(calculate_rouge_score(curr_caps[i],curr_caps[j]))\n",
    "    pair_wise_rouge.append(curr_score)\n",
    "    #print(curr_score)\n",
    "    #print(pair_wise_meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89389978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256\n"
     ]
    }
   ],
   "source": [
    "print(len(pair_wise_rouge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bb81ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63157894 0.63157894 0.33333333 0.375      0.38095238 0.19047619]\n",
      " [0.47058823 0.19047619 0.76190476 0.125      0.75       0.1       ]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array3 = np.array(pair_wise_rouge)\n",
    "print(numpy_array3[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4afbd907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair Averages rouge-2 f1:\n",
      "Pair 1: 0.27857406886982344\n",
      "Pair 2: 0.20146336965114797\n",
      "Pair 3: 0.17762976469962968\n",
      "Pair 4: 0.18142939410077463\n",
      "Pair 5: 0.1661502448008401\n",
      "Pair 6: 0.20930382019991026\n"
     ]
    }
   ],
   "source": [
    "column_averages = np.mean(numpy_array3, axis=0)\n",
    "\n",
    "# Print the column averages\n",
    "print(\"Pair Averages rouge-2 f1:\")\n",
    "for i, average in enumerate(column_averages):\n",
    "    print(f\"Pair {i+1}: {average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d53195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b3cdc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "876d51a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fb363b44730>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/c6/8c/bc5457de4c004b1a623b31f7bc8d0375fb699b7d67df11879098b4b7b7c8/bert_score-0.3.13-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fb363b449d0>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/c6/8c/bc5457de4c004b1a623b31f7bc8d0375fb699b7d67df11879098b4b7b7c8/bert_score-0.3.13-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m517.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (1.4.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (4.65.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (4.29.2)\n",
      "Collecting torch>=1.0.0\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m357.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: requests in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (2.30.0)\n",
      "Requirement already satisfied: numpy in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (1.23.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2022.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (4.3.0)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m998.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m995.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:05\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (3.12.0)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (3.0.3)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m867.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:07\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (61.2.0)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-16.0.5.post0.tar.gz (138 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (1.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (3.1.0)\n",
      "Requirement already satisfied: fsspec in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert-score) (2023.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.5.post0-py3-none-any.whl size=88273 sha256=27be5e82d52ed288ed2a2fb72c2c2330c0c649ac876f5f73a3a2348a944aabe0\n",
      "  Stored in directory: /home/soham/.cache/pip/wheels/2a/84/df/5f1bd338b4ba7d034f2cd0c4bf326539e54a46f26995bcd74e\n",
      "Successfully built lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, bert-score\n",
      "Successfully installed bert-score-0.3.13 cmake-3.26.4 lit-16.0.5.post0 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "369c7f09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m generated_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA cat is sitting on a mat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m reference_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA cat sits on the mat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m bert_score_value \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_bert_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bert_score_value)\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36mcalculate_bert_score\u001b[0;34m(generated_sentence, reference_sentence)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_bert_score\u001b[39m(generated_sentence, reference_sentence):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert sentences to tensors\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     generated_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenerated_sentence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     reference_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([reference_sentence])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Calculate BERTScore\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from bert_score import score\n",
    "\n",
    "def calculate_bert_score(generated_sentence, reference_sentence):\n",
    "    # Convert sentences to tensors\n",
    "    generated_tensor = torch.tensor([generated_sentence])\n",
    "    reference_tensor = torch.tensor([reference_sentence])\n",
    "\n",
    "    # Calculate BERTScore\n",
    "    P, R, F1 = score(generated_tensor, reference_tensor, lang='en', model_type='bert-base-uncased')\n",
    "\n",
    "    # Extract the BERTScore value\n",
    "    bert_score_value = F1.item()\n",
    "\n",
    "    return bert_score_value\n",
    "\n",
    "# Example usage\n",
    "generated_sentence = \"A cat is sitting on a mat\"\n",
    "reference_sentence = \"A cat sits on the mat\"\n",
    "bert_score_value = calculate_bert_score(generated_sentence, reference_sentence)\n",
    "print(\"BERTScore:\", bert_score_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f305ec19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m generated_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA cat is sitting on a mat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m reference_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA cat sits on the mat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m bert_score_value \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_bert_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bert_score_value)\n",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36mcalculate_bert_score\u001b[0;34m(generated_sentence, reference_sentence)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_bert_score\u001b[39m(generated_sentence, reference_sentence):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert sentences to tensors\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     generated_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenerated_sentence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     reference_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([reference_sentence])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Calculate BERTScore\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from bert_score import score\n",
    "\n",
    "def calculate_bert_score(generated_sentence, reference_sentence):\n",
    "    # Convert sentences to tensors\n",
    "    generated_tensor = torch.tensor([generated_sentence])\n",
    "    reference_tensor = torch.tensor([reference_sentence])\n",
    "\n",
    "    # Calculate BERTScore\n",
    "    P, R, F1 = score(generated_tensor, reference_tensor, lang='en', model_type='bert-base-uncased')\n",
    "\n",
    "    # Extract the BERTScore value\n",
    "    bert_score_value = F1.item()\n",
    "\n",
    "    return bert_score_value\n",
    "\n",
    "# Example usage\n",
    "generated_sentence = \"A cat is sitting on a mat\"\n",
    "reference_sentence = \"A cat sits on the mat\"\n",
    "bert_score_value = calculate_bert_score(generated_sentence, reference_sentence)\n",
    "print(\"BERTScore:\", bert_score_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9894824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████| 440M/440M [00:37<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_15190/240858931.py\", line 28, in <cell line: 28>\n",
      "    bert_score_value = calculate_bert_score(generated_sentence, reference_sentence)\n",
      "  File \"/tmp/ipykernel_15190/240858931.py\", line 18, in calculate_bert_score\n",
      "    scorer = BERTScorer(model_type='bert-base-uncased')\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/bert_score/scorer.py\", line 98, in __init__\n",
      "    self._model = get_model(self.model_type, self.num_layers, self.all_layers)\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/bert_score/utils.py\", line 255, in get_model\n",
      "    model = AutoModel.from_pretrained(model_type)\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 467, in from_pretrained\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 2542, in from_pretrained\n",
      "    f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 433, in load_state_dict\n",
      "    state_dict = loader(os.path.join(folder, shard_file))\n",
      "NameError: name 'safe_open' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from bert_score import BERTScorer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "def calculate_bert_score(generated_sentence, reference_sentence):\n",
    "    # Load the tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Tokenize the sentences\n",
    "    generated_tokens = tokenizer.tokenize(generated_sentence)\n",
    "    reference_tokens = tokenizer.tokenize(reference_sentence)\n",
    "\n",
    "    # Convert tokens to IDs\n",
    "    generated_ids = tokenizer.convert_tokens_to_ids(generated_tokens)\n",
    "    reference_ids = tokenizer.convert_tokens_to_ids(reference_tokens)\n",
    "\n",
    "    # Create BERTScorer\n",
    "    scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "\n",
    "    # Calculate BERTScore\n",
    "    _, _, bert_score_value = scorer.score(generated_ids, reference_ids)\n",
    "\n",
    "    return bert_score_value.item()\n",
    "\n",
    "# Example usage\n",
    "generated_sentence = \"A cat is sitting on a mat\"\n",
    "reference_sentence = \"A cat sits on the mat\"\n",
    "bert_score_value = calculate_bert_score(generated_sentence, reference_sentence)\n",
    "print(\"BERTScore:\", bert_score_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba71ea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-score in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (0.3.9)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fbec9c36070>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/bert-score/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting bert-score\n",
      "  Using cached bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: transformers in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (4.9.1)\n",
      "Collecting transformers\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fbec9350b80>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/5b/0b/e45d26ccd28568013523e04f325432ea88a442b4e3020b757cf4361f0120/transformers-4.30.2-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (1.4.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (4.65.0)\n",
      "Requirement already satisfied: numpy in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (1.23.1)\n",
      "Requirement already satisfied: matplotlib in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: requests in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (2.30.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from bert-score) (21.3)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: fsspec in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2022.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (11.7.101)\n",
      "Requirement already satisfied: networkx in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (3.1)\n",
      "Requirement already satisfied: sympy in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (11.4.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (2.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (11.7.91)\n",
      "Requirement already satisfied: jinja2 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (2.14.3)\n",
      "Requirement already satisfied: wheel in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (61.2.0)\n",
      "Requirement already satisfied: cmake in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (16.0.5.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from matplotlib->bert-score) (9.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->bert-score) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/soham/anaconda3/envs/my_env/lib/python3.9/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers, bert-score\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.12\n",
      "    Uninstalling huggingface-hub-0.0.12:\n",
      "      Successfully uninstalled huggingface-hub-0.0.12\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.9.1\n",
      "    Uninstalling transformers-4.9.1:\n",
      "      Successfully uninstalled transformers-4.9.1\n",
      "  Attempting uninstall: bert-score\n",
      "    Found existing installation: bert-score 0.3.9\n",
      "    Uninstalling bert-score-0.3.9:\n",
      "      Successfully uninstalled bert-score-0.3.9\n",
      "Successfully installed bert-score-0.3.13 huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade bert-score transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "468b8da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█████| 482/482 [00:00<00:00, 17.2kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|███| 899k/899k [00:00<00:00, 1.43MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 12.0MB/s]\n",
      "Downloading model.safetensors: 100%|███████| 1.42G/1.42G [02:03<00:00, 11.5MB/s]\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Saved figure to file:  visualize.png\n",
      "Figure(800x700)\n"
     ]
    }
   ],
   "source": [
    "!bert-score-show --lang en -r \"There are two bananas on the table.\" -c \"On the table are two apples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c67f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_env] *",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
