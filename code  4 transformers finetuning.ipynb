{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5140ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2018aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71266ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0ac38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7352e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 19:59:09.267115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datasets\n",
    "from transformers import VisionEncoderDecoderModel, AutoFeatureExtractor,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6602ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except (LookupError, OSError):\n",
    "    nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6f9e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.11.crossattention.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.11.attn.bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c274d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, AutoTokenizer\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8920ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vit-gpt-model/tokenizer_config.json',\n",
       " 'vit-gpt-model/special_tokens_map.json',\n",
       " 'vit-gpt-model/vocab.json',\n",
       " 'vit-gpt-model/merges.txt',\n",
       " 'vit-gpt-model/added_tokens.json',\n",
       " 'vit-gpt-model/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"vit-gpt-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05917644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21942ce2d57a4b25ae5d71147c3f988a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home1/sm21mtech14004/.cache/huggingface/datasets/imagefolder/default-f50bdc978128de85/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a28efab88614bc6b459056832772053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"imagefolder\", data_dir=\"../dataset/my_dataset/train\")['train'].train_test_split(test_size=0.2035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4ae4088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480FD9D150>, 'text': 'an aerial view of many motorcycles and bicycles are parked on the sidewalk'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7602B0>, 'text': 'a tennis court with a large metal structure in the background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1536x827 at 0x7F480E760610>, 'text': 'an aerial view of a road with a tower'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7607C0>, 'text': 'an aerial view of a road with a triangle shaped building in the middle of park'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1070x649 at 0x7F480E760A00>, 'text': 'red and white coloured building roundabout  ahead of it and green bushes on left side of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1127x759 at 0x7F480E7604C0>, 'text': 'a road divided by green grassy lanes with a tall residential building nearby'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760B80>, 'text': 'stage set up for the concert'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=738x382 at 0x7F480E7603A0>, 'text': 'aerial view of a building with a red roof and a lot of people'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7602B0>, 'text': 'a straight road having a tree and a red car on its side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7609D0>, 'text': 'a group of blue shades behind tall white building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760430>, 'text': 'a soccer ground on dirt field'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=981x599 at 0x7F480E760A00>, 'text': 'an aerial view of an empty road with a motorcycle on it . '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7601C0>, 'text': 'under construction area surrounded by green bushes'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=748x397 at 0x7F480E760760>, 'text': 'top view of a large building with and society surrounded by green bushes'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1155x653 at 0x7F480E760A60>, 'text': 'an aerial view of a road with people and trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1370x645 at 0x7F480E760610>, 'text': 'a large grassy area with walkway and trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760F40>, 'text': 'an aerial view of green bushes near by road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7607C0>, 'text': 'many under development buildings can be seen'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1364x711 at 0x7F480E7604C0>, 'text': 'an empty street with a green tarp covering the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760B80>, 'text': 'a lot of trees on green park in front of under construction building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760760>, 'text': 'an aerial view of basketball field next to volleyball court'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1476x733 at 0x7F480E7602B0>, 'text': 'two roads intersection with buildings on side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7609D0>, 'text': 'a map of india carved on a huge white pillar with iit hyderabad engraved on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=908x566 at 0x7F480E760430>, 'text': 'group of people standing with a gray colour under construction building in front of them'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760A00>, 'text': 'a town with lot of buildings and roads with green farms in the background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7604C0>, 'text': 'deserted area with bushes joined to road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1040x714 at 0x7F480E7601C0>, 'text': 'an aerial view of a curvy road in a rural area . '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760A60>, 'text': 'underc onstruction building in between a green land'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1460x757 at 0x7F480E760610>, 'text': 'a green wasteland having a road and a vehicle parked on the side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1229x663 at 0x7F480E760F40>, 'text': 'an aerial view of urban area with road in the middle of white tent and building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760670>, 'text': 'a road junction with four lanes roads'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7607C0>, 'text': 'an aerial view of a parking lot with many cars parked in it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=747x399 at 0x7F480E7604C0>, 'text': 'road with few vehicles on the road and people walking on the side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=961x520 at 0x7F480E760760>, 'text': 'a white dome in playground and buildings next to it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E7602B0>, 'text': 'an aerial view of empty road with parking space and large buildings around'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1085x654 at 0x7F480E7609D0>, 'text': 'an aerial view of urban area with road in the middle of white tent and building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760430>, 'text': 'many people stand near white tent'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1575x799 at 0x7F480E760670>, 'text': 'a view of road with buildings and green area'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760A00>, 'text': 'a large hall with white chairs and a green carpet on the floor'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7601C0>, 'text': 'huge construction side with multiple under construction buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=969x503 at 0x7F480E760760>, 'text': 'many cars in parking lot with building in the background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760610>, 'text': 'many people sitting under a tall red and white building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1693x838 at 0x7F480E7603A0>, 'text': 'a white and yellow coloured building with a construction site on its right'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760F40>, 'text': 'a red and white dom shaped cabin with many tall buildings near it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1041x685 at 0x7F480E7607C0>, 'text': 'a walkway surrounding a white tirangular tower'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760700>, 'text': 'a straight road having a tree and few vehicles parked under it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1269x616 at 0x7F480E7601C0>, 'text': 'black and white cars and a man standing in front of the car'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7602B0>, 'text': 'an aerial view of an large empty field with tall white buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7609D0>, 'text': 'an aerial view of basketball field next to volleyball court'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760430>, 'text': 'a large outdoor stage with chairs and people'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760670>, 'text': 'a tall under construction building near walkway and trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=924x533 at 0x7F480E7607C0>, 'text': 'an aerial view of sports field near the green field and lot of trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760A00>, 'text': 'a paved road with trees and people walking on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760760>, 'text': 'a lot of motorcycles parked in a parking lot next to building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1227x615 at 0x7F480E7602B0>, 'text': 'aerial view of a purple building with a man walking on the sidewalk'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=710x385 at 0x7F480E7603A0>, 'text': 'two tents are set up in grassy ground'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760CA0>, 'text': 'an aerial view of green field and under construction sites'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=773x428 at 0x7F480E760F40>, 'text': 'construction site having oval shaped entitiy and a shed'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=836x441 at 0x7F480E760700>, 'text': 'an aerial view of a lush green field with lot of trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1340x745 at 0x7F480E760A60>, 'text': 'an aerial view of green lawn with walkway and street lamp'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1484x690 at 0x7F480E7601C0>, 'text': 'one small and one big white tent surrounded by many people and few vehicles'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7609D0>, 'text': 'a group of building with lot of people on stairs '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=990x497 at 0x7F480E760430>, 'text': 'an under construction site on farm land'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=961x554 at 0x7F480E760670>, 'text': 'garden with road intersection'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=797x400 at 0x7F480E7607C0>, 'text': 'an aerial view of a small town with many buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760A00>, 'text': 'a green lawn with lot of trees in front of tall buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=938x606 at 0x7F480E760A60>, 'text': 'a residential complex with tall buildings and gardens'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1562x829 at 0x7F480E7602B0>, 'text': 'an aerial view of a factory with blue roof and trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7603A0>, 'text': 'tall white residential building and a road side of that'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=839x479 at 0x7F480E760CA0>, 'text': 'an auto standing near a person and a white vehicle behind it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1087x567 at 0x7F480E760F40>, 'text': 'a large building complex surrounded by lush green field '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1281x744 at 0x7F480E760B80>, 'text': 'many tall curved red colured building with green grassy areas infront of them'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760700>, 'text': 'a bulldozer driving on a road with sheds beside '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760A60>, 'text': 'a green grassy area and trees in front of buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1539x843 at 0x7F480E7609D0>, 'text': 'aerial view of a highway with a car driving on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760430>, 'text': 'people have gathered outside many food stalls and eating'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1140x537 at 0x7F480E760670>, 'text': 'a view of the road from above'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7607C0>, 'text': 'there are people walking down the street and vehicles on the side of the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7608E0>, 'text': 'an aerial view of green lawn with walkway and street lamp'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760700>, 'text': 'a group of building with lot of people on stairs '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7602B0>, 'text': 'people walking down on sidewalk next to stairs'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7603A0>, 'text': 'many cars in parking lot with building in the background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760430>, 'text': 'a new building is being constructed behind tall building and green lawn'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1293x816 at 0x7F480E760F40>, 'text': 'a green grassy land surrounding a white tall pillar'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7604C0>, 'text': 'many rocks surrounding a tall white monument'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7608E0>, 'text': 'a large building has yellow railing and green box in middle of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1155x674 at 0x7F480E760A60>, 'text': 'an aerial view of green lawn with street lamp'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760760>, 'text': 'a group of under construction buildings in a town with lots of trees around'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1115x587 at 0x7F480E7609D0>, 'text': 'many buildings and a circular intersection near large green area with lot of trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1414x744 at 0x7F480E760670>, 'text': 'a large grassy area with walkway and trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7601C0>, 'text': 'a parking lot with many cars and motercycles parked in it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=715x363 at 0x7F480E7604C0>, 'text': 'a man crossing a road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1481x850 at 0x7F480E760700>, 'text': 'a top view of an empty road with a tall building adjacent to it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7602B0>, 'text': 'a building with a lot of vehicles parked in front of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7603A0>, 'text': 'under construction building with dugged up land around'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760430>, 'text': '3 lane road approching to the lake and tall building on one side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=688x410 at 0x7F480E760610>, 'text': 'road with blue boards and white buses'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7601C0>, 'text': 'a group of people sitting on chairs and some are chatting'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7608E0>, 'text': 'many people gathered on green lawn in front of a tall building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760A60>, 'text': 'many cars parked on parking lot in front of tall building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7602B0>, 'text': 'an aerial view of people standing on a mud road surrounded by green bushes'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7609D0>, 'text': 'construction site with adjacent grassy wasteland'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1042x590 at 0x7F480E760A00>, 'text': 'an areial view of red and white building on green farm land'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1140x691 at 0x7F480E760670>, 'text': 'an aerial view of an intersection in a rural area . '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1142x670 at 0x7F480E7604C0>, 'text': 'many curved buildings with many solar panels on their terrace'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1353x660 at 0x7F480E760B80>, 'text': 'top view of building and parking ahead of that building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1150x592 at 0x7F480E760700>, 'text': 'aerial view of buildings on both side of road and roundabout at the center of the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7603A0>, 'text': 'construction site with round shaped structure in between along with a pond in visible'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7609D0>, 'text': 'few complete and few under construction buildings can be seen surrounded by green land'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760610>, 'text': 't intersection of roads situated on a wasteland and a truck running on the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7601C0>, 'text': 'an aerial view of ground with many people standing near the white tent'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1421x772 at 0x7F480E7604C0>, 'text': 'from top view'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760A60>, 'text': 'aerial view of a crane besides a lush green area'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=670x351 at 0x7F480E760CA0>, 'text': 'few blue industrial buildings surrounded by green field'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1564x861 at 0x7F480E7602B0>, 'text': 'aerial view of people standing below flag poles of different colous with buildings at a distance'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1710x887 at 0x7F480E760A00>, 'text': 'an aerial view of farm land with red soil'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760F40>, 'text': 'a tall building has lot of trees and green lawn in front of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1228x686 at 0x7F480E7601C0>, 'text': 'a white car running on the road with many signboards'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760B80>, 'text': 'a green carpet is on the floor with white plastic chairs'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1073x582 at 0x7F480E760700>, 'text': 'road with inverted v diversion parallel to construction site'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7603A0>, 'text': 'a large group of people gathered around a stage for an event'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7609D0>, 'text': 'many people gathered on green lawn in front of trees and building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7607C0>, 'text': '4 single lane road approching lake and 2 buildings each side of road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760610>, 'text': 'a morden architure building with small gardern and street light in front of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7601C0>, 'text': 'there are many chairs in the dome with a red carpet'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760A60>, 'text': 'an aerial view of a construction site with a road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=872x496 at 0x7F480E760CA0>, 'text': 'there is a woman walking down the street on left side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7602B0>, 'text': 'a top view of running track on green field surrounded by green farm land'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760A00>, 'text': 'an aerial view of a parking lot with many cars parked in it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1646x899 at 0x7F480E7607C0>, 'text': 'a view of sheds with blue roofs'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760F40>, 'text': 'aerial view of a road with green bushes'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=987x619 at 0x7F480E760B80>, 'text': 'a white car moving on a road with green lawns around the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1222x683 at 0x7F480E760700>, 'text': 'a huge white tent on the ground with red roof dom and basketball court in front of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7603A0>, 'text': 'construction site with green wasteland beside'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7608E0>, 'text': 'under construction area with roads around'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760A00>, 'text': 'bulldozer and few people in a wasteland having parking area on its side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1191x633 at 0x7F480E760610>, 'text': 'a road lined with lots of bushes and flowers'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1843x1006 at 0x7F480E7601C0>, 'text': 'a building with many windows and a crane on top'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1082x598 at 0x7F480E760A60>, 'text': 'ariel view of a huge construction site with green wasteland beside'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760CA0>, 'text': 'sandy wasteland consisting of a road and a vehicle on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1085x613 at 0x7F480E7603A0>, 'text': 'a group of people walking down a red carpet with lot of people standing around them'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1032x693 at 0x7F480E7602B0>, 'text': 'an aerial view of a building with a hole in the middle of roof'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7607C0>, 'text': 'an aerial view of town with tall buildings in the middle'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760F40>, 'text': 'several cranes surrounding a building and fenced by blue fencing'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760B80>, 'text': 'there is a man standing on the side of the road  next to the bike and white tent behind it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E760A60>, 'text': 'few buildings surrounded by farmlands and having 2 towers nearby the buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760700>, 'text': 'a top view of empty four lane highway'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1471x810 at 0x7F480E7608E0>, 'text': 'a top view of roundabout next to construction site'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=964x476 at 0x7F480E760A00>, 'text': 'an aerial view of a road with trees and a truck'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=986x577 at 0x7F480E760610>, 'text': 'a view of a large apartment building with a solar pannel on roof'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1272x617 at 0x7F480E760430>, 'text': 'consturction area with semi circular arrangments'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=901x490 at 0x7F480E7601C0>, 'text': 'a straight pathway having a construction site on its right'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760CA0>, 'text': 'a paved road with a white line with green bushes on both side and people are walking on road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760700>, 'text': 'a large building the under construction with workers working around'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1088x583 at 0x7F480E7602B0>, 'text': 'straight road having wasteland on one side and construction side on other side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7607C0>, 'text': 'an aerial view of a city with a lot of trees . '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760F40>, 'text': 'a large green lawn and trees in front of tall buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1603x892 at 0x7F480E760B80>, 'text': 'an aerial view of green area with white buildings and road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760670>, 'text': 'a group of people standing on green carpet for ceremony'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=947x535 at 0x7F480E760CA0>, 'text': 'construction site with a blue fencing and a crane'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=848x458 at 0x7F480E7608E0>, 'text': 'aerial view of a building site with a truck parked in front of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E760A00>, 'text': 'under development building covered by blue nets'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760610>, 'text': 'a green lawn in front of tall building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E760430>, 'text': 'few constructed and few under construction building beside a road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=957x459 at 0x7F480E7609D0>, 'text': 'wasteland consisting of a road with a bus running over it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7601C0>, 'text': 'a huge under construction building covered by net and a crane on top of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760700>, 'text': 'a large green farm land has buildings and road and mobile towers near by'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7608E0>, 'text': 'a group of people sitting on chairs and some are chatting'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7607C0>, 'text': 'a road with footpath has lot of people walking on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1646x883 at 0x7F480E760F40>, 'text': 'a straight road with an auto and a bike and people walking on the side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=947x510 at 0x7F480E760B80>, 'text': 'white cuboid structures on a pathway and a girl walking'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=961x452 at 0x7F480E760670>, 'text': 'a green farm land and road with many trees around'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=866x502 at 0x7F480E7601C0>, 'text': 'an aerial view of a roundabout with plants and  buses'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760760>, 'text': 'a tree on a wasteland and a red coloured car beside it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760A00>, 'text': 'many under construction buildings on a brown ground'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760610>, 'text': 'small water fountains below a big white tower'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760F40>, 'text': 'view of stage in parking with many vehicle'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1544x818 at 0x7F480E760A60>, 'text': 'a road with people some people walking and with some people chatting'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1142x618 at 0x7F480E7609D0>, 'text': 'an aerial view of a road with a car driving down it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=875x456 at 0x7F480E760700>, 'text': 'a group of people standing on one side and cars are parked on other end of the ground'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7608E0>, 'text': 'people are walking on street in front of building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1143x643 at 0x7F480E7603A0>, 'text': 'a top view of tall building with green lawn in front of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1420x660 at 0x7F480E7607C0>, 'text': 'road having multiple blue cabins on its side'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1191x653 at 0x7F480E760B80>, 'text': 'an aerial view of a grassy area with bushes and dirt road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760670>, 'text': 'an aerial view of green lawn with many people posing for photoshoot'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1217x599 at 0x7F480E7601C0>, 'text': 'a green wasteland having a road on its right and few vehicles parked on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760760>, 'text': 'many plants and flowers near concrete wall'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7608E0>, 'text': 'a top view of green practice nets'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760610>, 'text': 'a view of a large area with many buildings and trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1129x604 at 0x7F480E760F40>, 'text': 'a street with a car driving down it near tall buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1454x715 at 0x7F480E760A60>, 'text': 'a large number of multi storey buildings with construction site on a side '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1203x665 at 0x7F480E760670>, 'text': 'a top view of green lawn with lot of trees in front of tall buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E7602B0>, 'text': 'an aerial view of building and green lawn with construction site on background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1618x859 at 0x7F480E760700>, 'text': 'a green lawn in middle of tall building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1493x794 at 0x7F480E7603A0>, 'text': 'a white tower on a black triangular base'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7607C0>, 'text': 'a lot of people and trees on sidewalk near to the building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1146x661 at 0x7F480E760F40>, 'text': 'an aerial view of an urban area with tall buildings near green bushes'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1617x873 at 0x7F480E760B80>, 'text': 'an aerial view of a tall pillar on a park with a road in the background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7601C0>, 'text': 'a straight road having a tree and few vehicles parked under it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760760>, 'text': 'few workers working on constructing a multistorey building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=745x458 at 0x7F480E760700>, 'text': 'huge multi storey under-construction building beside a wasteland'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760430>, 'text': 'a building with many windows and a crane on top'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=765x424 at 0x7F480E760610>, 'text': 'green lawn on one end of the road and people walking on the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760A60>, 'text': 'an aerial view of ground with many people standing near the white tent'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760670>, 'text': 'red and white coloured building with mutiple windows'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1222x685 at 0x7F480E7604C0>, 'text': 'construction site adjacent to road and buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=925x576 at 0x7F480E7602B0>, 'text': 'a multistorey building having construction side beside '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7603A0>, 'text': 'large construction site beside a grassy wasteland'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E760430>, 'text': 'an aerial view of large field with lot of buildings and under construction area on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=785x439 at 0x7F480E760F40>, 'text': 'an aerial view of large building complex near the parking lot with farm land in the background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760B80>, 'text': 'small road beside the main road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=797x398 at 0x7F480E7601C0>, 'text': 'an aerial view of circular intersection in middle of green bushes '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1185x661 at 0x7F480E760760>, 'text': 'a long road surrounded by green field and trees'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1147x577 at 0x7F480E760A00>, 'text': 'a white car moving on a road with green lawns around the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1027x588 at 0x7F480E760700>, 'text': 'a road and a monumnet next to large green field'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760610>, 'text': 'under development building with dugged up land around'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1203x639 at 0x7F480E760A60>, 'text': 'an aerial view of farm land with lot trees and a long highway in the middle'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E760670>, 'text': 'a tree on a wasteland and a white coloured car beside it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1093x564 at 0x7F480E7601C0>, 'text': 'a construction site with multiple rods and a construction worker'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=783x439 at 0x7F480E7602B0>, 'text': 'a top view of a road with motorcycle'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7603A0>, 'text': 'a lot of buildings in a town with green trees in background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760430>, 'text': 'aerial view of a large industrial area with a blue roof'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1035x498 at 0x7F480E760610>, 'text': 'an aerial view of farm land with lot of trees and building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1170x547 at 0x7F480E7609D0>, 'text': 'a straight road with no turns and lot of bushes and flowers '}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1204x669 at 0x7F480E760B80>, 'text': 'construction site with adjacent grassy wasteland'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1004x462 at 0x7F480E760760>, 'text': 'some vehicles on road with large circular intersection in rural area'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=987x458 at 0x7F480E760A00>, 'text': 'green lawn on one end of the road and car moving on the road'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=989x563 at 0x7F480E7611B0>, 'text': 'a crane and a few under-construction buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=951x467 at 0x7F480E760700>, 'text': 'a road with large circular intersection'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E760A60>, 'text': 'under construction building surrounded by mud and dugged up land'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E760670>, 'text': 'gray colour multi storey building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1084x629 at 0x7F480E7601C0>, 'text': 'an aerial view of a building with a hole in the middle of roof'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7602B0>, 'text': 'a group of people gathered on ground'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760A00>, 'text': 'group of people gathered outside a building for an event with enthusiasm'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1450x763 at 0x7F480E760430>, 'text': 'construction area beside a building and green lawn'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E760610>, 'text': 'development site with around four unfinished building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1145x621 at 0x7F480E7609D0>, 'text': 'a view of road with red buildings on left'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E760B80>, 'text': 'a road with 3 lanes approching to tall buildings'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1332x644 at 0x7F480E7607C0>, 'text': 'a car moving on a road surrounded with green lanes and sign boards'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=743x397 at 0x7F480E760760>, 'text': 'aerial view of a green land and large building with a lot of blue roofs'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7611B0>, 'text': 'a new building is being constructed behind tall building and green lawn'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=905x483 at 0x7F480E760430>, 'text': 'many blue roof buildings near by green fields'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2688x1512 at 0x7F480E760A60>, 'text': 'a top view of a farm land with many curved buildings near it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=945x462 at 0x7F480E760670>, 'text': 'a green field with lot of trees has tall building on it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1145x652 at 0x7F480E7601C0>, 'text': 'a group of people standing outside a big white tent with some people on red carpet'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1281x657 at 0x7F480E7602B0>, 'text': 'a tall building with solar panel on roof has many buildings in background'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4608x2176 at 0x7F480E7608E0>, 'text': 'a line of motorcycles parked on a street'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x7F480E7611B0>, 'text': 'construction site near by dirt roads'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1506x917 at 0x7F480E760610>, 'text': 'an aerial view of an empty road in the middle of a city with green grass'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1564x893 at 0x7F480E7609D0>, 'text': 'long road with roundabout at center of the road and buildings on right side of it'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E760B80>, 'text': 'ariel view of a road and wasteland having a square shaped building'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x720 at 0x7F480E7607C0>, 'text': 'a view of a building with ramp and green lawn'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=3840x2160 at 0x7F480E7604C0>, 'text': 'a red carpet in the middle of white tent with lot of people on both the side of carpet'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2720x1530 at 0x7F480E7608E0>, 'text': 'the construction site features a gray building adorned with yellow railings and a blue safety net.'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1298x636 at 0x7F480E760430>, 'text': 'a long'}\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1053x568 at 0x7F480E760A60>, 'text': 'an aerial view of large green field with many buildings in the middle and a water body in the background'}\n"
     ]
    }
   ],
   "source": [
    "for i in (ds['test']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e5b5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee205e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42214b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# text preprocessing step\n",
    "def tokenization_fn(captions, max_target_length):\n",
    "    \"\"\"Run tokenization on captions.\"\"\"\n",
    "    labels = tokenizer(captions, \n",
    "                      padding=\"max_length\", \n",
    "                      max_length=max_target_length).input_ids\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe75e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_fn(image_paths, check_image=True):\n",
    "    \"\"\"\n",
    "    Run feature extraction on images\n",
    "    If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n",
    "    Otherwise, an exception will be thrown.\n",
    "    \"\"\"\n",
    "\n",
    "    model_inputs = {}\n",
    "\n",
    "    if check_image:\n",
    "        images = []\n",
    "        to_keep = []\n",
    "        for image_file in image_paths:\n",
    "            try:\n",
    "                img = image_file#image#Image.open(image_file)\n",
    "                images.append(img)\n",
    "                to_keep.append(True)\n",
    "            except Exception:\n",
    "                to_keep.append(False)\n",
    "    else:\n",
    "        images = [image_file for image_file in image_paths]\n",
    "\n",
    "    encoder_inputs = feature_extractor(images=images, return_tensors=\"np\")\n",
    "\n",
    "    return encoder_inputs.pixel_values\n",
    "\n",
    "def preprocess_fn(examples, max_target_length, check_image = True):\n",
    "    \"\"\"Run tokenization + image feature extraction\"\"\"\n",
    "    image_paths = examples['image']\n",
    "    captions = examples['text']    \n",
    "    \n",
    "    model_inputs = {}\n",
    "    # This contains image path column\n",
    "    model_inputs['labels'] = tokenization_fn(captions, max_target_length)\n",
    "    model_inputs['pixel_values'] = feature_extraction_fn(image_paths, check_image=check_image)\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a033d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_dataset = ds.map(\n",
    "    function=preprocess_fn,\n",
    "    batched=True,\n",
    "    fn_kwargs={\"max_target_length\": 128},\n",
    "    remove_columns=ds['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385faf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    output_dir=\"./image-captioning-output\",\n",
    "    save_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5a1073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f24782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: rouge_score in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from rouge_score) (1.23.3)\n",
      "Requirement already satisfied: six>=1.14.0 in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from rouge_score) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: click in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages (from nltk->rouge_score) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6954a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ignore_pad_token_for_loss = True\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    if ignore_pad_token_for_loss:\n",
    "        # Replace -100 in the labels as we can't decode them.\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds,\n",
    "                                                     decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds,\n",
    "                            references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acc5766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=processed_dataset['train'],\n",
    "    eval_dataset=processed_dataset['test'],\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb871a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 09:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.231237</td>\n",
       "      <td>38.152700</td>\n",
       "      <td>13.242200</td>\n",
       "      <td>31.224700</td>\n",
       "      <td>31.205900</td>\n",
       "      <td>11.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206117</td>\n",
       "      <td>40.550800</td>\n",
       "      <td>16.159600</td>\n",
       "      <td>34.018800</td>\n",
       "      <td>34.011800</td>\n",
       "      <td>10.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.197625</td>\n",
       "      <td>41.150600</td>\n",
       "      <td>16.203300</td>\n",
       "      <td>33.502800</td>\n",
       "      <td>33.553400</td>\n",
       "      <td>11.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195211</td>\n",
       "      <td>41.568600</td>\n",
       "      <td>17.718200</td>\n",
       "      <td>34.448700</td>\n",
       "      <td>34.372300</td>\n",
       "      <td>10.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.194698</td>\n",
       "      <td>41.496400</td>\n",
       "      <td>17.630400</td>\n",
       "      <td>34.663900</td>\n",
       "      <td>34.616800</td>\n",
       "      <td>11.308594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home1/sm21mtech14004/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=160, training_loss=0.23717291355133058, metrics={'train_runtime': 602.5153, 'train_samples_per_second': 8.299, 'train_steps_per_second': 0.266, 'total_flos': 9.0231945560064e+17, 'train_loss': 0.23717291355133058, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22d018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3e3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
